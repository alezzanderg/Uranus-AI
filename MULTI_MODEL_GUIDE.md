# ü§ñ Multi-Model AI Guide - Uranus-AI

Uranus-AI ahora soporta m√∫ltiples proveedores de IA, permiti√©ndote elegir el mejor modelo para cada tarea espec√≠fica.

## üåü Modelos Soportados

### üî• OpenAI
- **GPT-4 Turbo**: Modelo m√°s avanzado con 128k contexto y visi√≥n
- **GPT-4**: Excelente para razonamiento complejo
- **GPT-3.5 Turbo**: R√°pido y econ√≥mico para tareas generales

### üß† Anthropic Claude
- **Claude 3 Opus**: El m√°s poderoso para an√°lisis complejo
- **Claude 3 Sonnet**: Balance perfecto entre rendimiento y costo
- **Claude 3 Haiku**: El m√°s r√°pido para respuestas inmediatas

### üîç Google Gemini
- **Gemini Pro**: Modelo vers√°til de Google
- **Gemini Pro Vision**: Con capacidades de visi√≥n

### üöÄ xAI Grok
- **Grok Beta**: IA conversacional con conocimiento en tiempo real

### üíª DeepSeek
- **DeepSeek Coder**: Especializado en generaci√≥n y an√°lisis de c√≥digo
- **DeepSeek Chat**: Modelo conversacional general

### üè† Ollama (Local)
- **Llama 2**: Meta's Llama 2 ejecut√°ndose localmente
- **Code Llama**: Modelo especializado en c√≥digo local

### üåä Mistral
- **Mistral Large**: Modelo m√°s capaz de Mistral
- **Mistral Medium**: Rendimiento balanceado

### üéØ Cohere
- **Command R+**: Modelo avanzado con contexto largo

## üõ†Ô∏è Configuraci√≥n

### 1. Variables de Entorno

Copia y configura el archivo `.env`:

```bash
cp ai-backend/.env.example ai-backend/.env
```

### 2. API Keys Requeridas

```env
# OpenAI
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Claude
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google Gemini
GOOGLE_API_KEY=your_google_api_key_here

# xAI Grok
XAI_API_KEY=your_xai_api_key_here

# DeepSeek
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Mistral
MISTRAL_API_KEY=your_mistral_api_key_here

# Cohere
COHERE_API_KEY=your_cohere_api_key_here

# Ollama (local)
OLLAMA_BASE_URL=http://localhost:11434/v1
```

### 3. Configuraci√≥n de Modelos por Defecto

```env
DEFAULT_MODEL=gpt-4
FALLBACK_MODELS=["gpt-3.5-turbo", "claude-3-haiku", "gemini-pro"]
ENABLE_MODEL_SWITCHING=true
ENABLE_AUTO_FALLBACK=true
```

## üéØ Uso de M√∫ltiples Modelos

### 1. Selecci√≥n Autom√°tica de Modelo

El sistema puede recomendar el mejor modelo basado en la tarea:

```typescript
// En el frontend
const recommendations = await fetch('/api/v1/models/select', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    task_type: 'code_analysis',
    context_length: 8000,
    prefer_cost_effective: false
  })
});
```

### 2. Comparaci√≥n de Modelos

Compara m√∫ltiples modelos con el mismo prompt:

```typescript
const comparison = await fetch('/api/v1/models/compare', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    models: ['gpt-4', 'claude-3-opus', 'gemini-pro'],
    test_prompt: 'Explain this JavaScript function',
    criteria: ['quality', 'speed', 'cost']
  })
});
```

### 3. Uso Directo de Modelo Espec√≠fico

```typescript
const response = await fetch('/api/v1/models/generate', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    model_id: 'claude-3-opus',
    provider: 'anthropic',
    messages: [
      { role: 'user', content: 'Analyze this code for bugs' }
    ],
    temperature: 0.7
  })
});
```

## üìä Caracter√≠sticas por Modelo

| Modelo | Proveedor | Contexto | Costo/1K | Mejor Para |
|--------|-----------|----------|----------|------------|
| GPT-4 Turbo | OpenAI | 128K | $0.01 | An√°lisis complejo, visi√≥n |
| Claude 3 Opus | Anthropic | 200K | $0.015 | Razonamiento profundo |
| Claude 3 Sonnet | Anthropic | 200K | $0.003 | Balance costo/calidad |
| Claude 3 Haiku | Anthropic | 200K | $0.00025 | Respuestas r√°pidas |
| Gemini Pro | Google | 32K | $0.0005 | Tareas generales |
| Grok Beta | xAI | 131K | $0.005 | Conocimiento actual |
| DeepSeek Coder | DeepSeek | 16K | $0.0014 | Programaci√≥n |
| Llama 2 | Ollama | 4K | Gratis | Uso local/privado |

## üéõÔ∏è Configuraci√≥n Avanzada

### Fallback Autom√°tico

Si un modelo falla, el sistema autom√°ticamente intenta con modelos de respaldo:

```env
ENABLE_AUTO_FALLBACK=true
FALLBACK_MODELS=["gpt-3.5-turbo", "claude-3-haiku", "gemini-pro"]
```

### Optimizaci√≥n de Costos

Habilita la optimizaci√≥n autom√°tica de costos:

```env
ENABLE_COST_OPTIMIZATION=true
PREFER_COST_EFFECTIVE=true
```

### L√≠mites de Velocidad

Configura l√≠mites por modelo:

```env
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_PER_HOUR=1000
```

## üîÑ Integraci√≥n en el Frontend

### Selector de Modelo en UI

El AI Assistant ahora incluye un selector de modelo:

```typescript
// En aiAssistantView.ts
private createModelSelector(): HTMLElement {
  const selector = document.createElement('select');
  selector.className = 'ai-model-selector';
  
  // Cargar modelos disponibles
  this.loadAvailableModels().then(models => {
    models.forEach(model => {
      const option = document.createElement('option');
      option.value = model.id;
      option.textContent = `${model.name} (${model.provider})`;
      selector.appendChild(option);
    });
  });
  
  return selector;
}
```

### Chat con Modelo Espec√≠fico

```typescript
async sendMessage(message: string, modelId?: string) {
  const selectedModel = modelId || this.getSelectedModel();
  
  const response = await this.communicationService.sendMessage({
    message,
    model_id: selectedModel,
    context: await this.contextService.getCurrentContext()
  });
  
  return response;
}
```

## üìà Monitoreo y Analytics

### Estad√≠sticas de Uso

Obt√©n estad√≠sticas detalladas de uso:

```bash
curl http://localhost:8000/api/v1/models/stats
```

### Benchmarking

Ejecuta benchmarks autom√°ticos:

```bash
curl -X POST http://localhost:8000/api/v1/models/benchmark \
  -H "Content-Type: application/json" \
  -d '{
    "models": ["gpt-4", "claude-3-opus", "gemini-pro"],
    "test_prompts": [
      "Explain quantum computing",
      "Write a Python function to sort a list",
      "Debug this JavaScript code"
    ]
  }'
```

## üéØ Recomendaciones de Uso

### Para Chat General
1. **Claude 3 Sonnet** - Excelente balance
2. **GPT-4** - Respuestas de alta calidad
3. **Gemini Pro** - Opci√≥n econ√≥mica

### Para An√°lisis de C√≥digo
1. **DeepSeek Coder** - Especializado en c√≥digo
2. **Claude 3 Opus** - An√°lisis profundo
3. **GPT-4** - Versatilidad

### Para Respuestas R√°pidas
1. **Claude 3 Haiku** - M√°s r√°pido
2. **GPT-3.5 Turbo** - Econ√≥mico y r√°pido
3. **Gemini Pro** - Balance velocidad/costo

### Para Contexto Largo
1. **Claude 3 Sonnet** - 200K contexto
2. **GPT-4 Turbo** - 128K contexto
3. **Grok Beta** - 131K contexto

### Para Uso Local/Privado
1. **Code Llama** - Especializado en c√≥digo
2. **Llama 2** - Uso general
3. **Ollama** - F√°cil configuraci√≥n local

## üîß Soluci√≥n de Problemas

### Modelo No Disponible
```
Error: Client not configured for provider: anthropic
```
**Soluci√≥n**: Verifica que la API key est√© configurada en `.env`

### L√≠mite de Tokens Excedido
```
Error: Token limit exceeded
```
**Soluci√≥n**: Usa un modelo con mayor contexto o reduce el texto

### Fallback No Funciona
```
Error: All models failed
```
**Soluci√≥n**: Verifica que al menos un modelo de fallback est√© configurado

## üöÄ Pr√≥ximas Funcionalidades

- [ ] **Modelos Locales Adicionales**: Soporte para m√°s modelos Ollama
- [ ] **Fine-tuning**: Personalizaci√≥n de modelos
- [ ] **Embeddings**: B√∫squeda sem√°ntica avanzada
- [ ] **Multimodal**: Soporte completo para im√°genes y audio
- [ ] **Streaming Mejorado**: Streaming paralelo de m√∫ltiples modelos
- [ ] **Cache Inteligente**: Cache compartido entre modelos

## üí° Tips y Trucos

### 1. Combinar Modelos
Usa diferentes modelos para diferentes partes de una tarea:
- **DeepSeek Coder** para generar c√≥digo
- **Claude 3 Opus** para explicar el c√≥digo
- **GPT-4** para documentaci√≥n

### 2. Optimizaci√≥n de Costos
- Usa **Claude 3 Haiku** para tareas simples
- Reserva **GPT-4** para an√°lisis complejos
- Aprovecha **modelos locales** para desarrollo

### 3. Contexto Largo
- **Claude 3** para documentos largos
- **GPT-4 Turbo** para an√°lisis de repositorios completos
- **Grok** para informaci√≥n actualizada

---

¬°Con m√∫ltiples modelos, Uranus-AI se convierte en la herramienta de IA m√°s vers√°til para desarrollo! ü™êüöÄ

